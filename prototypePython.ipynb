{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b251039f-92d5-4fe3-af00-34802c4794c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mistralai\n",
      "  Downloading mistralai-1.9.3-py3-none-any.whl (426 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.3/426.3 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "Collecting eval-type-backport>=0.2.0\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/sid2019-6/.local/lib/python3.10/site-packages (from mistralai) (0.4.1)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in /home/sid2019-6/.local/lib/python3.10/site-packages (from mistralai) (2.11.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from mistralai) (2.9.0.post0)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from mistralai) (0.28.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.28.1->mistralai) (1.0.7)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx>=0.28.1->mistralai) (2020.6.20)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.28.1->mistralai) (4.8.0)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx>=0.28.1->mistralai) (3.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/sid2019-6/.local/lib/python3.10/site-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10.3->mistralai) (4.12.2)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/sid2019-6/.local/lib/python3.10/site-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.2.2)\n",
      "Installing collected packages: eval-type-backport, mistralai\n",
      "Successfully installed eval-type-backport-0.2.2 mistralai-1.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mistralai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c66bee-2b98-46e9-8bdc-0ed7d69b6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir une version json de la sortie du LLM\n",
    "import json\n",
    "def to_json(chat_response):\n",
    "    j_end = chat_response.find('}') + 1\n",
    "    j_part = chat_response[:j_end]\n",
    "\n",
    "    j = json.loads(j_part)\n",
    "    \n",
    "    if j_end == len(chat_response):\n",
    "        return j, \"rien\"\n",
    "        \n",
    "    t_part = chat_response[j_end:].lstrip()\n",
    "    return j, t_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3634f2f-899f-4547-b35e-eeb88dd0e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "memory_message = []\n",
    "\n",
    "def action_response(action, filenames, user_prompt, assistant_response):\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "    match action:\n",
    "        case \"create\" :\n",
    "            nbr = len(filenames)\n",
    "            for filename in filenames:\n",
    "                print(f\"   <--création du fichier '{filename}'-->\")\n",
    "            summary = f'{now} : Création de {\", \".join(filenames)}, {nbr} fichier(s)'\n",
    "\n",
    "        case \"delete\" :\n",
    "            nbr = len(filenames)\n",
    "            for filename in filenames:\n",
    "                print(f\"   <--suppression du fichier '{filename}'-->\")\n",
    "            summary = f'{now} : Suppression de {\", \".join(filenames)}, {nbr} fichier(s)'\n",
    "        case _:\n",
    "            summary = f'{now} : Échange sans action :  {user_prompt} → {assistant_response}'\n",
    "\n",
    "    memory_message.append(summary)\n",
    "    if len(memory_message) > 10:\n",
    "        memory_message.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a59f6b1c-9e2c-4319-b731-e7b6b7fd379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "\n",
    "API_KEY = \"\"\n",
    "MODEL = \"mistral-tiny\"\n",
    "\n",
    "client = Mistral(api_key=API_KEY)\n",
    "\n",
    "def s_prompt():\n",
    "    memory = \",\\n \".join(memory_message)\n",
    "    system_prompt = (\n",
    "        \"Tu es un assistant polyvalent capable de :\"\n",
    "    \n",
    "        \"1. Créer ou supprimer des fichiers selon les commandes reçues.\"\n",
    "        \"2. Répondre à des questions ou discuter simplement si aucune action sur les fichiers n’est demandée, exclusivement en français.\"\n",
    "    \n",
    "        \"Tu dois :\"\n",
    "        \"- Répondre uniquement avec un JSON structuré (jamais en dehors).\"\n",
    "        \"- Être précis et concis, sans explication supplémentaire.\"\n",
    "        \"- Utilise un ton naturel dans le champ 'response' (exemples : 'Je m’en occupe', 'C’est bon pour moi', 'Très bien', etc.), sans répéter les actions comme 'fichier créé'\"\n",
    "        \"- Déduire l'action correcte ou répondre normalement si aucun fichier n’est concerné.\"\n",
    "    \n",
    "        \"Format de la réponse JSON :\"\n",
    "        \"{\"\n",
    "          \"'action': 'create' | 'delete' | 'none',\"\n",
    "          \"'filename': ['nom_du_fichier.txt', ...],\"\n",
    "          \"'file_number': int,\"\n",
    "          \"'response': 'Message court et naturel'\"\n",
    "        \"}\" \n",
    "        \"\"\n",
    "        \"\"\n",
    "        \"Voici une mémoire des derniers échanges :\"\n",
    "        + memory\n",
    "    )\n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "\n",
    "def prompt_to_llm(prompt):\n",
    "    system_prompt = s_prompt()\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    chat_response = client.chat.complete(\n",
    "        model=MODEL,\n",
    "        messages = messages\n",
    "    )\n",
    "\n",
    "    response_content = chat_response.choices[0].message.content \n",
    "    return (chat_response, response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a051cb0-d7fa-4dd3-b0d6-4d6a1cb9118f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-24 16:57:30.733159\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "maintenant = datetime.now()\n",
    "print(maintenant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add1ce0f-bd57-4e2f-85a2-94b78ebe9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activer notre chatbot sur le terminal pour lui demander des choses\n",
    "\n",
    "def chatbot():\n",
    "    print(f\"Bienvenue sur votre ChatBot. Vous pouvez discuter avec lui mais aussi gérer vos fichiers (création et suppréssion).\")\n",
    "    while True:\n",
    "        user_input = input('Vous : ')\n",
    "\n",
    "        if user_input.lower() in [\"quit\",\"exit\",\"q\"]:\n",
    "            print(f\"Merci. À une prochaine fois.\")\n",
    "            break\n",
    "\n",
    "        chat_response, response = prompt_to_llm(user_input)  # envoie de l'input au LLM et récupération de sa réponse brut + content\n",
    "        print(\"Chatbot : \",end=\"\")  # chatbot s'apprête à répondre\n",
    "        j_part, t_part = to_json(response)\n",
    "\n",
    "        if t_part != 'rien':\n",
    "            print(t_part)\n",
    "        print(j_part['response'])\n",
    "        \n",
    "        action_response(j_part['action'], j_part['filename'], user_input, j_part['response']) \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe0a827-ff1b-4055-af3d-d5680757ef16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bienvenue sur votre ChatBot. Vous pouvez discuter avec lui mais aussi gérer vos fichiers (création et suppréssion).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Vous :  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merci. À une prochaine fois.\n"
     ]
    }
   ],
   "source": [
    "chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
